{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c08961db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c53243",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ab3a19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data\n",
    "fashion_mnist_data, fashion_mnist_info = tfds.load(name='fashion_mnist',with_info=True,as_supervised=True)\n",
    "\n",
    "\n",
    "#Split into train,test variables\n",
    "fashion_train, fashion_test = fashion_mnist_data['train'],fashion_mnist_data['test']\n",
    "\n",
    "#Calculate validation samples count (10% of train data)\n",
    "num_validation_samples = len(fashion_train) * .1\n",
    "\n",
    "#Cast the value to a proper Int \n",
    "num_validation_samples = tf.cast(num_validation_samples,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bcae3cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scale the data.\n",
    "#To be passed as arguement to map.\n",
    "def Scale(image,label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image /= 255\n",
    "    return image,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "293a6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale our data: (We get a value between 0 and 1)\n",
    "\n",
    "scaled_train_and_validation_data = fashion_train.map(Scale)\n",
    "scaled_test_data = fashion_test.map(Scale)\n",
    "\n",
    "#Shuffle the data:\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "fashion_train_and_validation_shuffled = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "\n",
    "#Split train/ validation:\n",
    "validation_data = fashion_train_and_validation_shuffled.take(num_validation_samples)\n",
    "train_data = fashion_train_and_validation_shuffled.skip(num_validation_samples)\n",
    "\n",
    "\n",
    "#Batch train data:\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "#We don't require to batch the validation and test, but the model expects it\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = scaled_test_data.batch(len(scaled_test_data))\n",
    "\n",
    "validation_inputs, validation_outputs = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd294192",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5520a07d",
   "metadata": {},
   "source": [
    "### Outline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "eb95b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = 10\n",
    "hidden_layer_width = 50\n",
    "\n",
    "#Create the model:\n",
    "model = tf.keras.Sequential(\n",
    "                [\n",
    "                    tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "                    tf.keras.layers.MaxPool2D(pool_size=(2,2),strides=2),\n",
    "                    tf.keras.layers.Flatten(),\n",
    "                    tf.keras.layers.Dense(hidden_layer_width,activation='relu'),\n",
    "                    tf.keras.layers.Dense(output_size,activation='softmax')\n",
    "                    \n",
    "                ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34c5f76",
   "metadata": {},
   "source": [
    "### Optimizer and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4ccef55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de7eec",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b1003303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "540/540 - 16s - loss: 0.4827 - accuracy: 0.8357 - val_loss: 0.3506 - val_accuracy: 0.8777\n",
      "Epoch 2/10\n",
      "540/540 - 14s - loss: 0.3183 - accuracy: 0.8882 - val_loss: 0.3060 - val_accuracy: 0.8905\n",
      "Epoch 3/10\n",
      "540/540 - 15s - loss: 0.2788 - accuracy: 0.9020 - val_loss: 0.2722 - val_accuracy: 0.8977\n",
      "Epoch 4/10\n",
      "540/540 - 16s - loss: 0.2535 - accuracy: 0.9099 - val_loss: 0.2640 - val_accuracy: 0.9017\n",
      "Epoch 5/10\n",
      "540/540 - 16s - loss: 0.2352 - accuracy: 0.9162 - val_loss: 0.2472 - val_accuracy: 0.9113\n",
      "Epoch 6/10\n",
      "540/540 - 16s - loss: 0.2177 - accuracy: 0.9215 - val_loss: 0.2423 - val_accuracy: 0.9102\n",
      "Epoch 7/10\n",
      "540/540 - 16s - loss: 0.2035 - accuracy: 0.9273 - val_loss: 0.2109 - val_accuracy: 0.9207\n",
      "Epoch 8/10\n",
      "540/540 - 17s - loss: 0.1881 - accuracy: 0.9320 - val_loss: 0.2192 - val_accuracy: 0.9153\n",
      "Epoch 9/10\n",
      "540/540 - 16s - loss: 0.1775 - accuracy: 0.9359 - val_loss: 0.1861 - val_accuracy: 0.9297\n",
      "Epoch 10/10\n",
      "540/540 - 15s - loss: 0.1655 - accuracy: 0.9407 - val_loss: 0.1797 - val_accuracy: 0.9353\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c0899dbfd0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "model.fit(train_data,epochs=NUM_EPOCHS,verbose=2,validation_data=(validation_inputs,validation_outputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "233e5ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2587 - accuracy: 0.9130\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy is 91%, this could mean we are slighly overfitting on the train data\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25cc10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3-TF2.0]",
   "language": "python",
   "name": "conda-env-py3-TF2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
